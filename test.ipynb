{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhs2Lp08hSJ2C2C44QTDWR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b4b940ce4d4e4616a75b05dc656aaf6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "User Input:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_491834cf24dc4054b7bf93c9824cee42",
            "placeholder": "Ketik pertanyaan Anda di sini...",
            "style": "IPY_MODEL_a1904e83b7df4adba62361d78dde8e51",
            "value": ""
          }
        },
        "491834cf24dc4054b7bf93c9824cee42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1904e83b7df4adba62361d78dde8e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11a567fe7d75423ea2cd7873b79a322f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Kirim",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d0036f92a5694b5090f03b96944fd7b2",
            "style": "IPY_MODEL_4da93f4d819e4d3b93eb128223ff322f",
            "tooltip": ""
          }
        },
        "d0036f92a5694b5090f03b96944fd7b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4da93f4d819e4d3b93eb128223ff322f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3e1f70d73abf4bc7a7c7dfb9730a58e2": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_e05f395c19814d69bb93c209c777cf2b",
            "msg_id": "",
            "outputs": []
          }
        },
        "e05f395c19814d69bb93c209c777cf2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bryanbayup/my-dotfiles/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim keras-tuner imbalanced-learn Sastrawi sentencepiece seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu_36DqYCW2O",
        "outputId": "793e4770-0eca-4df9-8d5d-00277bb57989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=8e4fbd8b49afd22e26821b0bc4cb8c6cfa639403afff89535109bf7e4cd29fff\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: Sastrawi, kt-legacy, seqeval, keras-tuner\n",
            "Successfully installed Sastrawi-1.0.1 keras-tuner-1.4.7 kt-legacy-1.0.5 seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download FastText\n",
        "!wget -O id.tar.gz \"https://www.dropbox.com/scl/fi/sju4o3keikox69euw51vy/id.tar.gz?rlkey=5jr3ijtbdwfahq7xcgig28qvy&e=1&st=gntzkzeo&dl=1\"\n",
        "!tar -xzf id.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfaW2FTgMC1V",
        "outputId": "4682a3d2-ff9d-4ba0-9d33-0f964867b043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-08 12:32:52--  https://www.dropbox.com/scl/fi/sju4o3keikox69euw51vy/id.tar.gz?rlkey=5jr3ijtbdwfahq7xcgig28qvy&e=1&st=gntzkzeo&dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc631b975b0a539f30f71c43bf24.dl.dropboxusercontent.com/cd/0/inline/Cf3i5YL1lZEcmik-UMCmVbyBTmQzq-IL83qMHKmC-y1FGXBFxCqf-suYxFYAGvkc4inODeibXrkTyFB1M1fQS9CkT2zK30u6kZWGlaJUhmXXvwBaW9ZKCIciXpM-WEcyzrk/file?dl=1# [following]\n",
            "--2024-12-08 12:32:52--  https://uc631b975b0a539f30f71c43bf24.dl.dropboxusercontent.com/cd/0/inline/Cf3i5YL1lZEcmik-UMCmVbyBTmQzq-IL83qMHKmC-y1FGXBFxCqf-suYxFYAGvkc4inODeibXrkTyFB1M1fQS9CkT2zK30u6kZWGlaJUhmXXvwBaW9ZKCIciXpM-WEcyzrk/file?dl=1\n",
            "Resolving uc631b975b0a539f30f71c43bf24.dl.dropboxusercontent.com (uc631b975b0a539f30f71c43bf24.dl.dropboxusercontent.com)... 162.125.69.15, 2620:100:6025:15::a27d:450f\n",
            "Connecting to uc631b975b0a539f30f71c43bf24.dl.dropboxusercontent.com (uc631b975b0a539f30f71c43bf24.dl.dropboxusercontent.com)|162.125.69.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/Cf0ypbOwqpL3Hg10hg5G-C5vyhQ1xWAlnh-EOLTccjj9zDsQ0tFac4D6A-z8ZSSQjM_tARdhj-BFuufFDT2BjhsvOAS7fF1t-r36PHtR0du43yhrYQyvWB6agK404n9oawpGCVLl6_xFu-nbIWg1jdIfdI6rrF6cREY-KcQuCl1GH_WeusuXdeM7nsww7lXbY6xTnmXF10_6okio4jNnP7IPqA7n1sMqCx1yXa-3qKyhghFzdUSt2z6Q0CLM6fmURp5gEzM7YlKhehM_qD8rqrY8uxQDmUs7as-Ry75l_zvJUkHO4-uxUzd16HKDKXyOI1BBHXuqErs-MRu1sp3-JK5Gv2kTMMX6-ZGjDKqJRcgV-g/file?dl=1 [following]\n",
            "--2024-12-08 12:32:53--  https://uc631b975b0a539f30f71c43bf24.dl.dropboxusercontent.com/cd/0/inline2/Cf0ypbOwqpL3Hg10hg5G-C5vyhQ1xWAlnh-EOLTccjj9zDsQ0tFac4D6A-z8ZSSQjM_tARdhj-BFuufFDT2BjhsvOAS7fF1t-r36PHtR0du43yhrYQyvWB6agK404n9oawpGCVLl6_xFu-nbIWg1jdIfdI6rrF6cREY-KcQuCl1GH_WeusuXdeM7nsww7lXbY6xTnmXF10_6okio4jNnP7IPqA7n1sMqCx1yXa-3qKyhghFzdUSt2z6Q0CLM6fmURp5gEzM7YlKhehM_qD8rqrY8uxQDmUs7as-Ry75l_zvJUkHO4-uxUzd16HKDKXyOI1BBHXuqErs-MRu1sp3-JK5Gv2kTMMX6-ZGjDKqJRcgV-g/file?dl=1\n",
            "Reusing existing connection to uc631b975b0a539f30f71c43bf24.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2333351997 (2.2G) [application/binary]\n",
            "Saving to: ‘id.tar.gz’\n",
            "\n",
            "id.tar.gz           100%[===================>]   2.17G  21.2MB/s    in 1m 46s  \n",
            "\n",
            "2024-12-08 12:34:40 (20.9 MB/s) - ‘id.tar.gz’ saved [2333351997/2333351997]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import (Dense, Input, Dropout, Bidirectional, LSTM, Conv1D, GlobalMaxPooling1D,\n",
        "                                     TimeDistributed, Embedding, GlobalAveragePooling1D, Layer, Lambda)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import pickle\n",
        "import os\n",
        "import random\n",
        "import nltk\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "from keras_tuner import HyperModel, RandomSearch\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from nltk.corpus import stopwords\n",
        "from seqeval.metrics import classification_report as seq_classification_report\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTZbrFVvM3UZ",
        "outputId": "70841832-1504-4be6-8244-5a3eb70f5a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------\n",
        "# Load FastText\n",
        "# --------------------------------------\n",
        "try:\n",
        "    fasttext_model = KeyedVectors.load_word2vec_format('id.vec', binary=False)\n",
        "    print(\"FastText 'id.vec' berhasil dimuat.\")\n",
        "except Exception as e:\n",
        "    print(f\"Gagal memuat 'id.vec': {e}\")\n",
        "    raise ValueError(\"Gagal memuat FastText.\")\n",
        "\n",
        "# --------------------------------------\n",
        "# Load Data\n",
        "# Pastikan 'data2.json' adalah file yang berisi dataset terakhir yang Anda berikan.\n",
        "# --------------------------------------\n",
        "with open('data2.json', 'r', encoding='utf-8') as f:\n",
        "    conversations = json.load(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzvL6orlP-r3",
        "outputId": "ce653659-7ff9-4987-84a1-70b9f166b7c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText 'id.vec' berhasil dimuat.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------\n",
        "# Ekstrak Data\n",
        "# --------------------------------------\n",
        "def char_offset_to_token_labels(utterance, entities, tokenizer=lambda x: x.split()):\n",
        "    tokens = tokenizer(utterance)\n",
        "    labels = [\"O\"] * len(tokens)\n",
        "    char_pos = 0\n",
        "    token_ranges = []\n",
        "    for t in tokens:\n",
        "        start_pos = char_pos\n",
        "        end_pos = start_pos + len(t)\n",
        "        token_ranges.append((start_pos, end_pos))\n",
        "        char_pos = end_pos + 1\n",
        "    for ent in entities:\n",
        "        ent_start = ent['start']\n",
        "        ent_end = ent['end']\n",
        "        ent_type = ent['entity'].upper()\n",
        "        ent_token_positions = []\n",
        "        for i, (ts, te) in enumerate(token_ranges):\n",
        "            if not (te <= ent_start or ts >= ent_end):\n",
        "                ent_token_positions.append(i)\n",
        "        if len(ent_token_positions) > 0:\n",
        "            labels[ent_token_positions[0]] = \"B-\" + ent_type\n",
        "            for p in ent_token_positions[1:]:\n",
        "                labels[p] = \"I-\" + ent_type\n",
        "    return tokens, labels\n",
        "\n",
        "user_utterances = []\n",
        "intents = []\n",
        "entity_labels = []\n",
        "\n",
        "for conv in conversations:\n",
        "    for turn in conv[\"turns\"]:\n",
        "        if turn[\"speaker\"] == \"user\":\n",
        "            utt = turn[\"utterance\"]\n",
        "            ents = turn.get(\"entities\", [])\n",
        "            intent = turn.get(\"intent\", \"None\")\n",
        "            tokens, ner_tags = char_offset_to_token_labels(utt, ents)\n",
        "            user_utterances.append(tokens)\n",
        "            intents.append(intent)\n",
        "            entity_labels.append(ner_tags)"
      ],
      "metadata": {
        "id": "A-cFv97-P_3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------\n",
        "# Preprocessing Text\n",
        "# --------------------------------------\n",
        "with open('stopword_list_tala.txt', 'r', encoding='utf-8') as f:\n",
        "    stop_words = f.read().splitlines()\n",
        "stop_words = set(word.strip().lower() for word in stop_words)\n",
        "\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = clean_text(text)\n",
        "    tokens = text.split()\n",
        "    tokens = [w for w in tokens if w not in stop_words]\n",
        "    tokens = [stemmer.stem(w) for w in tokens]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "utterances_joined = [' '.join(utt) for utt in user_utterances]\n",
        "utterances_clean = [preprocess_text(u) for u in utterances_joined]\n",
        "\n",
        "df_data = pd.DataFrame({\n",
        "    'utterances': utterances_joined,\n",
        "    'intent': intents,\n",
        "    'entities': entity_labels,\n",
        "    'utterances_clean': utterances_clean\n",
        "})\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df_data['intent_label'] = label_encoder.fit_transform(df_data['intent'])\n",
        "\n",
        "# Balance data\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X = df_data.index.values.reshape(-1, 1)\n",
        "y = df_data['intent_label']\n",
        "X_ros, y_ros = ros.fit_resample(X, y)\n",
        "df_balanced = df_data.loc[X_ros.flatten()].reset_index(drop=True)\n",
        "df_balanced['intent_label'] = y_ros\n",
        "df_balanced['intent'] = label_encoder.inverse_transform(df_balanced['intent_label'])"
      ],
      "metadata": {
        "id": "fdMA4_sNQIgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------\n",
        "# Split Data for Intent Classification\n",
        "# --------------------------------------\n",
        "texts = df_balanced['utterances_clean'].tolist()\n",
        "labels = df_balanced['intent_label'].tolist()\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts,\n",
        "    labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")\n",
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='')\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "val_sequences = tokenizer.texts_to_sequences(val_texts)\n",
        "max_seq_length = max(max(len(seq) for seq in train_sequences), max(len(seq) for seq in val_sequences))\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_seq_length, padding='post')\n",
        "val_padded = pad_sequences(val_sequences, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "num_classes = len(label_encoder.classes_)\n",
        "train_labels_cat = to_categorical(train_labels, num_classes=num_classes)\n",
        "val_labels_cat = to_categorical(val_labels, num_classes=num_classes)\n",
        "\n",
        "embedding_dim = 300  # Gunakan embedding dim yang sama seperti fasttext\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, idx in word_index.items():\n",
        "    if word in fasttext_model:\n",
        "        embedding_matrix[idx] = fasttext_model[word]\n",
        "    else:\n",
        "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))"
      ],
      "metadata": {
        "id": "mnu5khNLQQgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------\n",
        "# NER Data\n",
        "# --------------------------------------\n",
        "all_labels = set()\n",
        "for tags in df_balanced['entities']:\n",
        "    for t in tags:\n",
        "        if t != 'O':\n",
        "            all_labels.add(t)\n",
        "all_labels.add('O')\n",
        "all_labels = sorted(list(all_labels))\n",
        "ner_label_encoder = {label: idx for idx, label in enumerate(all_labels)}\n",
        "ner_label_decoder = {idx: label for label, idx in ner_label_encoder.items()}\n",
        "\n",
        "def encode_tags(tags, max_len):\n",
        "    tag_ids = [ner_label_encoder[t] for t in tags]\n",
        "    tag_ids = tag_ids[:max_len] + [ner_label_encoder['O']]*(max_len - len(tag_ids))\n",
        "    return tag_ids\n",
        "\n",
        "def text_to_sequence(text):\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    return seq[0]\n",
        "\n",
        "X_ner = []\n",
        "Y_ner = []\n",
        "for i, row in df_balanced.iterrows():\n",
        "    seq = text_to_sequence(row['utterances_clean'])\n",
        "    seq_padded = seq[:max_seq_length] + [0]*(max_seq_length - len(seq))\n",
        "    X_ner.append(seq_padded)\n",
        "    tag_ids = encode_tags(row['entities'], max_seq_length)\n",
        "    Y_ner.append(tag_ids)\n",
        "\n",
        "X_ner = np.array(X_ner)\n",
        "Y_ner = np.array(Y_ner)\n",
        "Y_ner = to_categorical(Y_ner, num_classes=len(ner_label_encoder))\n",
        "\n",
        "train_texts_ner, val_texts_ner, train_labels_ner, val_labels_ner = train_test_split(\n",
        "    X_ner,\n",
        "    Y_ner,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "aCJ8hifyQsjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------\n",
        "# Attention Layer\n",
        "# --------------------------------------\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name='att_weight', shape=(input_shape[-1], 1),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "        self.b = self.add_weight(name='att_bias', shape=(1,),\n",
        "                                 initializer='zeros', trainable=True)\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        e = tf.squeeze(tf.tensordot(x, self.W, axes=1), axis=-1) + self.b\n",
        "        alpha = tf.nn.softmax(e)\n",
        "        alpha = tf.expand_dims(alpha, axis=-1)\n",
        "        context = x * alpha\n",
        "        return tf.reduce_sum(context, axis=1)  # shape: (batch, features)\n",
        "\n",
        "# --------------------------------------\n",
        "# Model Intent dengan BiLSTM + Attention\n",
        "# --------------------------------------\n",
        "def build_intent_model(embedding_matrix, max_seq_length, num_classes, l2_reg=1e-3):\n",
        "    inputs = Input(shape=(max_seq_length,), dtype='int32')\n",
        "    emb = Embedding(input_dim=embedding_matrix.shape[0],\n",
        "                    output_dim=embedding_matrix.shape[1],\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=max_seq_length,\n",
        "                    trainable=True, mask_zero=True)(inputs)\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3))(emb)\n",
        "    att = AttentionLayer()(x)\n",
        "    dense = Dense(128, activation='relu', kernel_regularizer=l2(l2_reg))(att)\n",
        "    dropout = Dropout(0.5)(dense)\n",
        "    outputs = Dense(num_classes, activation='softmax')(dropout)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model_intent = build_intent_model(embedding_matrix, max_seq_length, num_classes)\n",
        "early_intent = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "model_intent.fit(\n",
        "    train_padded, train_labels_cat,\n",
        "    validation_data=(val_padded, val_labels_cat),\n",
        "    epochs=30, batch_size=16,\n",
        "    callbacks=[early_intent]\n",
        ")\n",
        "\n",
        "# --------------------------------------\n",
        "# Model NER dengan BiLSTM + Attention\n",
        "# --------------------------------------\n",
        "def build_ner_model(embedding_matrix, max_seq_length, num_entities, l2_reg=1e-3):\n",
        "    inputs = Input(shape=(max_seq_length,))\n",
        "    emb = Embedding(input_dim=embedding_matrix.shape[0],\n",
        "                    output_dim=embedding_matrix.shape[1],\n",
        "                    weights=[embedding_matrix],\n",
        "                    trainable=True)(inputs) # mask_zero dihapus\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3))(emb)\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3))(x)\n",
        "\n",
        "    # Tetap gunakan TimeDistributed Dense untuk output NER\n",
        "    td = TimeDistributed(Dense(num_entities, activation='softmax'))(x)\n",
        "    model = Model(inputs, td)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model_ner = build_ner_model(embedding_matrix, max_seq_length, len(ner_label_encoder))\n",
        "early_ner = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "model_ner.fit(\n",
        "    train_texts_ner, train_labels_ner,\n",
        "    validation_data=(val_texts_ner, val_labels_ner),\n",
        "    epochs=30, batch_size=16,\n",
        "    callbacks=[early_ner]\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "loss_intent, acc_intent = model_intent.evaluate(val_padded, val_labels_cat)\n",
        "print(\"Akurasi Intent:\", acc_intent)\n",
        "\n",
        "loss_ner, acc_ner = model_ner.evaluate(val_texts_ner, val_labels_ner)\n",
        "print(\"Akurasi NER:\", acc_ner)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLUYhPBhQvLH",
        "outputId": "edee19c3-010a-468d-e057-981cff04e442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'attention_layer' (of type AttentionLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 138ms/step - accuracy: 0.3174 - loss: 1.7083 - val_accuracy: 0.5429 - val_loss: 1.2930\n",
            "Epoch 2/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.5790 - loss: 1.2170 - val_accuracy: 0.8857 - val_loss: 0.8327\n",
            "Epoch 3/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8422 - loss: 0.7461 - val_accuracy: 0.8714 - val_loss: 0.4988\n",
            "Epoch 4/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9133 - loss: 0.4557 - val_accuracy: 0.9143 - val_loss: 0.3347\n",
            "Epoch 5/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9553 - loss: 0.2707 - val_accuracy: 0.9286 - val_loss: 0.2823\n",
            "Epoch 6/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9833 - loss: 0.2241 - val_accuracy: 0.9143 - val_loss: 0.3241\n",
            "Epoch 7/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9956 - loss: 0.1787 - val_accuracy: 0.9286 - val_loss: 0.2854\n",
            "Epoch 8/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9831 - loss: 0.1716 - val_accuracy: 0.9286 - val_loss: 0.2499\n",
            "Epoch 9/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9848 - loss: 0.1787 - val_accuracy: 0.9429 - val_loss: 0.2441\n",
            "Epoch 10/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9968 - loss: 0.1383 - val_accuracy: 0.9429 - val_loss: 0.2528\n",
            "Epoch 11/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.9929 - loss: 0.1462 - val_accuracy: 0.9429 - val_loss: 0.2696\n",
            "Epoch 12/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.1232 - val_accuracy: 0.9286 - val_loss: 0.2480\n",
            "Epoch 13/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9968 - loss: 0.1158 - val_accuracy: 0.9429 - val_loss: 0.2522\n",
            "Epoch 14/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9994 - loss: 0.1082 - val_accuracy: 0.9143 - val_loss: 0.2417\n",
            "Epoch 15/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.1005 - val_accuracy: 0.9286 - val_loss: 0.2376\n",
            "Epoch 16/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.9988 - loss: 0.0964 - val_accuracy: 0.9429 - val_loss: 0.2119\n",
            "Epoch 17/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0928 - val_accuracy: 0.9429 - val_loss: 0.2026\n",
            "Epoch 18/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0849 - val_accuracy: 0.9286 - val_loss: 0.2130\n",
            "Epoch 19/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0810 - val_accuracy: 0.9286 - val_loss: 0.2073\n",
            "Epoch 20/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9939 - loss: 0.0899 - val_accuracy: 0.9143 - val_loss: 0.3003\n",
            "Epoch 21/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9985 - loss: 0.0771 - val_accuracy: 0.9571 - val_loss: 0.1790\n",
            "Epoch 22/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0741 - val_accuracy: 0.9429 - val_loss: 0.1783\n",
            "Epoch 23/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0735 - val_accuracy: 0.9429 - val_loss: 0.1920\n",
            "Epoch 24/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9973 - loss: 0.0734 - val_accuracy: 0.9571 - val_loss: 0.1559\n",
            "Epoch 25/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0627 - val_accuracy: 0.9571 - val_loss: 0.1437\n",
            "Epoch 26/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0598 - val_accuracy: 0.9571 - val_loss: 0.1449\n",
            "Epoch 27/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0574 - val_accuracy: 0.9571 - val_loss: 0.1498\n",
            "Epoch 28/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0551 - val_accuracy: 0.9571 - val_loss: 0.1443\n",
            "Epoch 29/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0523 - val_accuracy: 0.9571 - val_loss: 0.1287\n",
            "Epoch 30/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0490 - val_accuracy: 0.9571 - val_loss: 0.1239\n",
            "Epoch 1/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 130ms/step - accuracy: 0.5755 - loss: 1.8185 - val_accuracy: 0.7365 - val_loss: 0.8204\n",
            "Epoch 2/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.7393 - loss: 0.7836 - val_accuracy: 0.7603 - val_loss: 0.7469\n",
            "Epoch 3/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7693 - loss: 0.6187 - val_accuracy: 0.7937 - val_loss: 0.6429\n",
            "Epoch 4/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.7835 - loss: 0.5910 - val_accuracy: 0.8079 - val_loss: 0.5777\n",
            "Epoch 5/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.8131 - loss: 0.4948 - val_accuracy: 0.8238 - val_loss: 0.5364\n",
            "Epoch 6/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8239 - loss: 0.4574 - val_accuracy: 0.8238 - val_loss: 0.5179\n",
            "Epoch 7/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.8338 - loss: 0.4606 - val_accuracy: 0.8302 - val_loss: 0.5073\n",
            "Epoch 8/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8430 - loss: 0.4028 - val_accuracy: 0.8381 - val_loss: 0.4885\n",
            "Epoch 9/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8545 - loss: 0.3894 - val_accuracy: 0.8349 - val_loss: 0.4644\n",
            "Epoch 10/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.8604 - loss: 0.3772 - val_accuracy: 0.8476 - val_loss: 0.4667\n",
            "Epoch 11/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.8668 - loss: 0.3481 - val_accuracy: 0.8571 - val_loss: 0.4669\n",
            "Epoch 12/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.8597 - loss: 0.3462 - val_accuracy: 0.8619 - val_loss: 0.4839\n",
            "Epoch 13/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9029 - loss: 0.2756 - val_accuracy: 0.8651 - val_loss: 0.4296\n",
            "Epoch 14/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8974 - loss: 0.2809 - val_accuracy: 0.8698 - val_loss: 0.4530\n",
            "Epoch 15/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.8985 - loss: 0.2742 - val_accuracy: 0.8730 - val_loss: 0.4186\n",
            "Epoch 16/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8994 - loss: 0.2710 - val_accuracy: 0.8746 - val_loss: 0.4440\n",
            "Epoch 17/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9151 - loss: 0.2298 - val_accuracy: 0.8762 - val_loss: 0.4384\n",
            "Epoch 18/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.9047 - loss: 0.2484 - val_accuracy: 0.8762 - val_loss: 0.4409\n",
            "Epoch 19/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - accuracy: 0.9231 - loss: 0.2222 - val_accuracy: 0.8794 - val_loss: 0.4196\n",
            "Epoch 20/30\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9236 - loss: 0.2108 - val_accuracy: 0.8968 - val_loss: 0.4653\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9434 - loss: 0.1442\n",
            "Akurasi Intent: 0.9571428298950195\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8662 - loss: 0.4546\n",
            "Akurasi NER: 0.8730159401893616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------\n",
        "# Simpan Model\n",
        "# --------------------------------------\n",
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('encoders', exist_ok=True)\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "model_intent.save('models/model_intent.keras')\n",
        "model_ner.save('models/model_ner.keras')\n",
        "\n",
        "with open('encoders/tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('encoders/label_encoder.pickle', 'wb') as handle:\n",
        "    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('encoders/ner_label_encoder.pickle', 'wb') as handle:\n",
        "    pickle.dump(ner_label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "df_utterances = df_balanced[['utterances', 'intent', 'utterances_clean']].reset_index(drop=True)\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(df_utterances['utterances_clean'])\n",
        "with open('data/vectorizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(vectorizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "intent_animal_mapping = {\n",
        "    \"Melaporkan Hewan Terlantar\": [\"kucing\", \"anjing\"],\n",
        "    \"Mendiagnosis Gejala\": [\"kucing\", \"anjing\"],\n",
        "    \"Rekomendasi Penanganan Awal\": [\"kucing\", \"anjing\"],\n",
        "    \"Konfirmasi Laporan\": [\"kucing\", \"anjing\"],\n",
        "    \"Tindak Lanjut Laporan\": [\"kucing\", \"anjing\"],\n",
        "    \"Rekomendasi Tindakan\": [\"kucing\", \"anjing\"]\n",
        "}\n",
        "\n",
        "def predict_intent(text):\n",
        "    text_clean = preprocess_text(text)\n",
        "    seq = tokenizer.texts_to_sequences([text_clean])\n",
        "    padded = pad_sequences(seq, maxlen=max_seq_length, padding='post')\n",
        "    pred = model_intent.predict(padded)\n",
        "    predicted_label = np.argmax(pred, axis=1)[0]\n",
        "    return label_encoder.inverse_transform([predicted_label])[0]\n",
        "\n",
        "def predict_entities(text):\n",
        "    text_clean = preprocess_text(text)\n",
        "    seq = tokenizer.texts_to_sequences([text_clean])\n",
        "    padded = pad_sequences(seq, maxlen=max_seq_length, padding='post')\n",
        "    pred = model_ner.predict(padded)\n",
        "    pred_labels = np.argmax(pred[0], axis=-1)\n",
        "    tokens = tokenizer.sequences_to_texts(seq)[0].split()\n",
        "    entities = []\n",
        "    for idx, label_id in enumerate(pred_labels[:len(tokens)]):\n",
        "        label = ner_label_decoder[label_id]\n",
        "        if label != 'O':\n",
        "            entities.append({'entity': label.split('-')[1].lower(), 'value': tokens[idx]})\n",
        "    return entities\n",
        "\n",
        "def adjust_intent(intent, entities):\n",
        "    predicted_animals = intent_animal_mapping.get(intent, None)\n",
        "    entity_animals = [ent['value'].lower() for ent in entities if ent['entity'] == 'animal']\n",
        "    if entity_animals and predicted_animals:\n",
        "        user_animal = entity_animals[0]\n",
        "        if user_animal not in predicted_animals:\n",
        "            for i_name, animals in intent_animal_mapping.items():\n",
        "                if user_animal in animals:\n",
        "                    intent = i_name\n",
        "                    break\n",
        "            else:\n",
        "                intent = None\n",
        "    return intent\n",
        "\n",
        "def get_default_response():\n",
        "    default_responses = [\n",
        "        \"Maaf, saya belum bisa menjawab pertanyaan Anda.\",\n",
        "        \"Mohon diperjelas, saya belum mengerti konteksnya.\",\n",
        "        \"Silakan berikan informasi lebih detail.\",\n",
        "        \"Maaf, saya hanya diprogram untuk menjawab mengenai kucing dan anjing.\",\n",
        "        \"Saya sarankan konsultasi langsung ke dokter hewan.\"\n",
        "    ]\n",
        "    return random.choice(default_responses)\n",
        "\n",
        "def get_response(user_input, intent=None, entities=None):\n",
        "    # Untuk kesederhanaan, kita berikan respon tergantung intent:\n",
        "    # Jika tidak puas dengan ini, Anda bisa membuat mapping intent ke response yang lebih baik.\n",
        "    if intent == \"Mendiagnosis Gejala\":\n",
        "        return \"Berdasarkan gejalanya, kemungkinan ada masalah kesehatan. Saya sarankan segera periksakan ke dokter hewan.\"\n",
        "    elif intent == \"Rekomendasi Penanganan Awal\":\n",
        "        return \"Cobalah langkah penanganan awal seperti menjaga kebersihan, memberikan makanan ringan, dan konsultasikan ke dokter hewan jika berlanjut.\"\n",
        "    else:\n",
        "        return get_default_response()\n",
        "\n",
        "dialog_history = []\n",
        "MAX_HISTORY = 2\n",
        "\n",
        "def predict_intent_multi_turn(dialog_history, current_input):\n",
        "    history_context = dialog_history[-MAX_HISTORY:] if len(dialog_history) > MAX_HISTORY else dialog_history\n",
        "    combined_input = \" \".join(history_context + [current_input])\n",
        "    return predict_intent(combined_input)\n",
        "\n",
        "def predict_entities_multi_turn(dialog_history, current_input):\n",
        "    history_context = dialog_history[-MAX_HISTORY:] if len(dialog_history) > MAX_HISTORY else dialog_history\n",
        "    combined_input = \" \".join(history_context + [current_input])\n",
        "    return predict_entities(combined_input)\n",
        "\n",
        "def chatbot_response_multi_turn(user_input):\n",
        "    dialog_history.append(user_input)\n",
        "    intent = predict_intent_multi_turn(dialog_history, user_input)\n",
        "    entities = predict_entities_multi_turn(dialog_history, user_input)\n",
        "    adjusted = adjust_intent(intent, entities)\n",
        "    if adjusted is None:\n",
        "        response = get_default_response()\n",
        "    else:\n",
        "        response = get_response(user_input, adjusted, entities)\n",
        "        if not response:\n",
        "            response = get_default_response()\n",
        "    return response"
      ],
      "metadata": {
        "id": "eaS0OgN0Q9uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------\n",
        "# TESTING DENGAN PERTANYAAN YANG DIMINTA\n",
        "# Gunakan data \"conv_043\", \"conv_044\", \"conv_045\" yang telah Anda berikan.\n",
        "# --------------------------------------\n",
        "\n",
        "print(\"=== Test Model dengan Pertanyaan dari conv_043 ===\")\n",
        "dialog_history.clear()\n",
        "test_turns_043 = [\n",
        "    \"Saya melihat seekor kucing sakit di depan toko.\",\n",
        "    \"Kucingnya dalam keadaan sehat\"\n",
        "]\n",
        "\n",
        "for t in test_turns_043:\n",
        "    print(\"User:\", t)\n",
        "    resp = chatbot_response_multi_turn(t)\n",
        "    print(\"Chatbot:\", resp, \"\\n\")\n",
        "\n",
        "print(\"=== Test Model dengan Pertanyaan dari conv_044 ===\")\n",
        "dialog_history.clear()\n",
        "test_turns_044 = [\n",
        "    \"Anjing saya tidak nafsu makan dan sering diare. Apa yang terjadi?\",\n",
        "    \"Tidak, hanya diare saja.\"\n",
        "]\n",
        "\n",
        "for t in test_turns_044:\n",
        "    print(\"User:\", t)\n",
        "    resp = chatbot_response_multi_turn(t)\n",
        "    print(\"Chatbot:\", resp, \"\\n\")\n",
        "\n",
        "print(\"=== Test Model dengan Pertanyaan dari conv_045 ===\")\n",
        "dialog_history.clear()\n",
        "test_turns_045 = [\n",
        "    \"Kucing saya sering mengeluarkan air mata dan matanya terlihat merah.\",\n",
        "    \"Ya, ada renovasi rumah dengan banyak debu.\"\n",
        "]\n",
        "\n",
        "for t in test_turns_045:\n",
        "    print(\"User:\", t)\n",
        "    resp = chatbot_response_multi_turn(t)\n",
        "    print(\"Chatbot:\", resp, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5wuETpDRBZx",
        "outputId": "8135d12b-feb2-4f2b-b548-0bdb9ee33cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Test Model dengan Pertanyaan dari conv_043 ===\n",
            "User: Saya melihat seekor kucing sakit di depan toko.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'attention_layer' (of type AttentionLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819ms/step\n",
            "Chatbot: Saya sarankan konsultasi langsung ke dokter hewan. \n",
            "\n",
            "User: Kucingnya dalam keadaan sehat\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Chatbot: Saya sarankan konsultasi langsung ke dokter hewan. \n",
            "\n",
            "=== Test Model dengan Pertanyaan dari conv_044 ===\n",
            "User: Anjing saya tidak nafsu makan dan sering diare. Apa yang terjadi?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Chatbot: Berdasarkan gejalanya, kemungkinan ada masalah kesehatan. Saya sarankan segera periksakan ke dokter hewan. \n",
            "\n",
            "User: Tidak, hanya diare saja.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Chatbot: Berdasarkan gejalanya, kemungkinan ada masalah kesehatan. Saya sarankan segera periksakan ke dokter hewan. \n",
            "\n",
            "=== Test Model dengan Pertanyaan dari conv_045 ===\n",
            "User: Kucing saya sering mengeluarkan air mata dan matanya terlihat merah.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Chatbot: Berdasarkan gejalanya, kemungkinan ada masalah kesehatan. Saya sarankan segera periksakan ke dokter hewan. \n",
            "\n",
            "User: Ya, ada renovasi rumah dengan banyak debu.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Chatbot: Cobalah langkah penanganan awal seperti menjaga kebersihan, memberikan makanan ringan, dan konsultasikan ke dokter hewan jika berlanjut. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pastikan file data sudah diupload, misalnya data2.json\n",
        "with open('data2.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "with open('stopword_list_tala.txt', 'r', encoding='utf-8') as f:\n",
        "    stop_words = f.read().splitlines()\n",
        "stop_words = set(w.strip().lower() for w in stop_words)\n",
        "\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = clean_text(text)\n",
        "    tokens = text.split()\n",
        "    tokens = [w for w in tokens if w not in stop_words]\n",
        "    tokens = [stemmer.stem(w) for w in tokens]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Membangun knowledge base berupa list dari (user_utterance_clean, bot_response)\n",
        "# Setiap conversation, akan iterate turns.\n",
        "# Setiap kali menemukan turn user,cek turn berikutnya apakah bot ada respons\n",
        "# Jika ya, simpan (user_utterance_clean, bot_utterance) ke knowledge base\n",
        "\n",
        "knowledge_base = []\n",
        "for conv in data:\n",
        "    turns = conv[\"turns\"]\n",
        "    for i in range(len(turns)-1):\n",
        "        if turns[i][\"speaker\"] == \"user\" and turns[i+1][\"speaker\"] == \"bot\":\n",
        "            user_utt = turns[i][\"utterance\"]\n",
        "            bot_utt = turns[i+1][\"utterance\"]\n",
        "            user_utt_clean = preprocess_text(user_utt)\n",
        "            knowledge_base.append((user_utt_clean, bot_utt))\n",
        "\n",
        "df_kb = pd.DataFrame(knowledge_base, columns=[\"user_clean\",\"bot_response\"])\n",
        "\n",
        "# Vectorize user_utterance_clean untuk similarity\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df_kb[\"user_clean\"])\n",
        "\n",
        "def get_best_response(user_input):\n",
        "    # Preprocess query\n",
        "    user_query_clean = preprocess_text(user_input)\n",
        "    q_vec = vectorizer.transform([user_query_clean])\n",
        "    sims = cosine_similarity(q_vec, X)  # (1, n)\n",
        "    best_idx = sims[0].argmax()\n",
        "    best_score = sims[0][best_idx]\n",
        "    # Threshold opsional, misal jika similarity < 0.2 balas default\n",
        "    if best_score < 0.2:\n",
        "        return \"Maaf, saya belum memiliki informasi yang sesuai.\"\n",
        "    else:\n",
        "        return df_kb[\"bot_response\"].iloc[best_idx]\n",
        "\n",
        "# Contoh pengujian\n",
        "test_input = \"Kucing saya sering batuk dan hidungnya berair. Apa yang salah?\"\n",
        "response = get_best_response(test_input)\n",
        "print(\"User:\", test_input)\n",
        "print(\"Chatbot:\", response)\n",
        "\n",
        "test_input2 = \"Anjing saya tidak mau makan dan dia mencret\"\n",
        "response2 = get_best_response(test_input2)\n",
        "print(\"User:\", test_input2)\n",
        "print(\"Chatbot:\", response2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHTFcW6oOS-f",
        "outputId": "41d49945-195f-48d2-bfa6-fc24a1503541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Kucing saya sering batuk dan hidungnya berair. Apa yang salah?\n",
            "Chatbot: Gejala ini dapat menunjukkan Infeksi Saluran Pernapasan Atas. Apakah kucing Anda sering terpapar udara dingin atau debu?\n",
            "User: Anjing saya tidak mau makan dan dia mencret\n",
            "Chatbot: Jika tetap tidak mau makan selama lebih dari 24 jam, segera bawa anjing Anda ke dokter hewan untuk pemeriksaan lebih lanjut.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```bash\n",
        "    {\n",
        "        \"conversation_id\": \"conv_001\",\n",
        "        \"turns\": [\n",
        "            {\n",
        "                \"speaker\": \"user\",\n",
        "                \"utterance\": \"Saya melihat seekor kucing sakit di depan toko.\",\n",
        "                \"entities\": [\n",
        "                    {\n",
        "                        \"entity\": \"animal\",\n",
        "                        \"value\": \"kucing\",\n",
        "                        \"start\": 15,\n",
        "                        \"end\": 21\n",
        "                    },\n",
        "                    {\n",
        "                        \"entity\": \"location\",\n",
        "                        \"value\": \"depan toko\",\n",
        "                        \"start\": 29,\n",
        "                        \"end\": 39\n",
        "                    }\n",
        "                ],\n",
        "                \"intent\": \"Melaporkan Hewan Terlantar\"\n",
        "            },\n",
        "            {\n",
        "                \"speaker\": \"bot\",\n",
        "                \"utterance\": \"Terima kasih atas laporannya. Apakah kucing tersebut menunjukkan gejala seperti demam atau muntah?\",\n",
        "                \"entities\": [],\n",
        "                \"intent\": \"Mendiagnosis Gejala\"\n",
        "            },\n",
        "            {\n",
        "                \"speaker\": \"user\",\n",
        "                \"utterance\": \"Kucing terlihat demam dan bersin-bersin.\",\n",
        "                \"entities\": [\n",
        "                    {\n",
        "                        \"entity\": \"animal\",\n",
        "                        \"value\": \"kucing\",\n",
        "                        \"start\": 0,\n",
        "                        \"end\": 6\n",
        "                    },\n",
        "                    {\n",
        "                        \"entity\": \"symptom\",\n",
        "                        \"value\": \"demam\",\n",
        "                        \"start\": 15,\n",
        "                        \"end\": 20\n",
        "                    },\n",
        "                    {\n",
        "                        \"entity\": \"symptom\",\n",
        "                        \"value\": \"bersin-bersin\",\n",
        "                        \"start\": 25,\n",
        "                        \"end\": 39\n",
        "                    }\n",
        "                ],\n",
        "                \"intent\": \"Mendiagnosis Gejala\"\n",
        "            },\n",
        "            {\n",
        "                \"speaker\": \"bot\",\n",
        "                \"utterance\": \"Kucing tersebut mungkin terkena Feline Calicivirus. Sebaiknya segera hubungi komunitas terdekat melalui fitur emergency.\",\n",
        "                \"entities\": [],\n",
        "                \"intent\": \"Rekomendasi Penanganan Awal\"\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "{\n",
        "        \"conversation_id\": \"conv_011\",\n",
        "        \"turns\": [\n",
        "            {\n",
        "                \"speaker\": \"user\",\n",
        "                \"utterance\": \"Saya menemukan seekor anjing dengan perut membesar di pinggir jalan.\",\n",
        "                \"entities\": [\n",
        "                    {\n",
        "                        \"entity\": \"animal\",\n",
        "                        \"value\": \"anjing\",\n",
        "                        \"start\": 15,\n",
        "                        \"end\": 21\n",
        "                    },\n",
        "                    {\n",
        "                        \"entity\": \"symptom\",\n",
        "                        \"value\": \"perut membesar\",\n",
        "                        \"start\": 28,\n",
        "                        \"end\": 43\n",
        "                    },\n",
        "                    {\n",
        "                        \"entity\": \"location\",\n",
        "                        \"value\": \"pinggir jalan\",\n",
        "                        \"start\": 47,\n",
        "                        \"end\": 60\n",
        "                    }\n",
        "                ],\n",
        "                \"intent\": \"Melaporkan Hewan Terlantar\"\n",
        "            },\n",
        "            {\n",
        "                \"speaker\": \"bot\",\n",
        "                \"utterance\": \"Perut membesar dapat menjadi gejala Penyakit Cushing. Sebaiknya gunakan fitur emergency untuk melaporkan anjing ini.\",\n",
        "                \"entities\": [],\n",
        "                \"intent\": \"Rekomendasi Penanganan Awal\"\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "\n"
      ],
      "metadata": {
        "id": "OqZQk1jPT90K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# get_best_response(user_input) -> string\n",
        "\n",
        "dialog_history = []\n",
        "MAX_HISTORY = 2  # banyaknya turn sebelumnya yang akan digabung\n",
        "\n",
        "def combined_context(new_input):\n",
        "    # Menggabungkan turn terakhir di dialog_history dengan current input\n",
        "    # untuk mempertahankan konteks multi-turn.\n",
        "    history_context = dialog_history[-MAX_HISTORY:] if len(dialog_history) > MAX_HISTORY else dialog_history\n",
        "    combined = \" \".join(history_context + [new_input])\n",
        "    return combined\n",
        "\n",
        "# Input widget\n",
        "input_box = widgets.Text(\n",
        "    placeholder='Ketik pertanyaan Anda di sini...',\n",
        "    description='User Input:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "send_button = widgets.Button(\n",
        "    description='Kirim',\n",
        "    disabled=False,\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def on_send_clicked(b):\n",
        "    user_input = input_box.value.strip()\n",
        "    if user_input:\n",
        "        dialog_history.append(user_input)\n",
        "        # Buat query dengan konteks multi-turn\n",
        "        query_with_context = combined_context(user_input)\n",
        "        response = get_best_response(query_with_context)\n",
        "        with output_area:\n",
        "            print(f\"User: {user_input}\")\n",
        "            print(f\"Chatbot: {response}\\n\")\n",
        "    input_box.value = \"\"  # kosongkan setelah kirim\n",
        "\n",
        "send_button.on_click(on_send_clicked)\n",
        "\n",
        "display(input_box, send_button, output_area)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "b4b940ce4d4e4616a75b05dc656aaf6b",
            "491834cf24dc4054b7bf93c9824cee42",
            "a1904e83b7df4adba62361d78dde8e51",
            "11a567fe7d75423ea2cd7873b79a322f",
            "d0036f92a5694b5090f03b96944fd7b2",
            "4da93f4d819e4d3b93eb128223ff322f",
            "3e1f70d73abf4bc7a7c7dfb9730a58e2",
            "e05f395c19814d69bb93c209c777cf2b"
          ]
        },
        "id": "E8PLVn8lUuol",
        "outputId": "0484f13e-d11d-4781-ec7c-ea0f0cfedd2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', description='User Input:', placeholder='Ketik pertanyaan Anda di sini...')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4b940ce4d4e4616a75b05dc656aaf6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='Kirim', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11a567fe7d75423ea2cd7873b79a322f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e1f70d73abf4bc7a7c7dfb9730a58e2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hzc-7_DlVBqx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}